---
layout: post
title: Моделирование высшей нервной деятельности
tags:
- здоровье
- мозг
- человек
categories:
- Всячина
- Я. Ты. Мы. Они.
---
<article><p class="page-intro">Доктор физико-математических наук А. ЖДАНОВ, заведующий Отделом имитационных систем Института системного программирования РАН.</p>
<p><b>Моделирование работы мозга</b> — одна из самых интересных научных проблем нашего столетия. В сороковых годах, когда вышли в свет книга <b>Норберта Винера «Кибернетика, или Управление и связь в животном и в машине»</b>, повесть <b>«Путешествие длиной в век»<sup>&nbsp;*</sup></b> <b>Владимирa Тендряковa<b> и другие научные работы на эту тему, когда появились и начали распространяться ЭВМ, проблема перешла из области научной фантастики в область реальных теоретических исследований и практического моделирования.</p>
<q><p><b><sup>&nbsp;*&nbsp;</sup></b>(В ней писатель решал проблемы жизни и смерти, записи и переноса в другое тело человеческой психики, интеллекта и другие аналогичные вопросы, сегодня всерьез обсуждаемые учеными).<br>
(см. «Наука и жизнь» №№ 9—12, 1963 г.)</p></q>
<p>Однако увлекательность проблемы оказала ей дурную услугу. Неоднократно эта тема страдала от некомпетентных или недобросовестных интерпретаторов, претерпевая необоснованные, но весьма захватывающие дух взлеты, обескураживающие и тяжелые своими последствиями спады, периоды забвения. Кажется, лишь в последние десять лет волнение улеглось и исследования в этой области протекают в сравнительно деловой и спокойной обстановке.</p>
<p>Пережив все коллизии, тематика раздробилась на множество отдельных направлений. Сегодня само слово <b>«кибернетика»</b> произносят редко. Речь обычно идет о теории управления, нейрофизиологии, искусственном интеллекте, распознавании образов, представлении информации и принятии решений, нейронных сетях, робототехнике, искусственной жизни и многом другом. </p>
<p>Специалисты разных направлений иногда с трудом понимают друг друга, неохотно объединяются и часто по-разному понимают даже цели своих исследований.</p>
<p>Выделяют два основных подхода к исследованию и моделированию высшей нервной деятельности — <b>имитационный и прагматический</b>. </p>
<p><b>Имитационный подход</b> имеет целью сымитировать как результат работы мозга, так и сам принцип его действия. Специалисты этого направления говорят: «Нам интересно понять, как именно работает мозг». </p>
<p><b>Прагматический подход</b>, напротив, ставит целью получить практически полезные результаты любым подходящим способом, совершенно не соотносясь с принципами работы мозга. Специалисты этого направления говорят: </p>
<q><p>«Нам важно любыми методами научить машину решать сложные интеллектуальные задачи, какие умеет решать только человек, — и желательно быстрее, точнее и лучше. А как работает мозг, мы не знаем и, наверное, не узнаем никогда».</p></q>
<p>К примеру, ставится задача — создать устройство для управления велосипедом. Специалист-прагматик составит систему дифференциальных уравнений, описывающих движение велосипеда, решит ее и, записав решение в память управляющей системы, тем самым научит ее управлять велосипедом. Специалист имитационного подхода скажет: «Позвольте, но в голове трехлетнего ребенка нет никаких дифференциальных уравнений, однако он, набив несколько синяков, успешно и достаточно быстро обучается езде на велосипеде! Нет, природа решает задачу по-другому. Давайте искать, как она это делает».</p>
<p>В действительности оба подхода дополняют друг друга. Как правило, основные идеи и направления появляются в стане имитаторов, после чего скрупулезные прагматики доводят их до стадии практически полезных разработок.</p>
<p>Не ставя целью дать обзор всех достижений в области моделирования высшей нервной деятельности, остановимся на том понимании вопроса и тех результатах, которые получены научной группой, составляющей Отдел имитационных систем (http:// www.ispras.ru/~zhdanov) Института системного программирования РАН (http:// www.ispras.ru/).</p>
<p>Разрабатываемую нами имитационную модель нервной системы мы называем системой автономного адаптивного управления (ААУ).</b></p>

<h2>НЕРВНАЯ СИСТЕМА КАК АВТОНОМНАЯ АДАПТИВНАЯ СИСТЕМА УПРАВЛЕНИЯ</h2>
<p>Договоримся о терминах. Обычно при моделировании нервных систем в точных науках пользуются следующими синонимами биологических объектов.</p>
<table cellpadding="1" cellspacing="2" style="text-align: center">
<tbody><tr>
<td><b>Кибернетические объекты</b></td>
<td><b>Биологические объекты</b></td>
</tr>
<tr>
<td>Среда</td>
<td>Объект управления (ОУ)</td>
</tr>
<tr>
<td>Управляющая система (УС)</td>
<td>Датчики</td>
</tr>
<tr>
<td>Исполнители</td>
<td>Окружающая среда</td>
</tr>
<tr>
<td>Организм</td>
<td>Нервная система и мозг</td>
</tr>
<tr>
<td>Рецепторы</td>
<td>Эффекторы</td>
</tr>
</tbody></table><br>
<p>Прежде чем приступать к конструированию модели нервной системы, необходимо наложить ряд ограничений на нашу будущую модель.</p>
<p>Конструктор, разрабатывающий какую-либо систему, всегда ограничен «исходными условиями». Его задача — построить систему так, чтобы она была для них оптимальна. Поэтому при одинаковых исходных условиях два конструктора часто независимо друг от друга приходят к одному и тому же результату. Посмотрите, например, как сегодня похожи друг на друга хорошие автомобили разных марок — даже их форма вынужденно диктуется аэродинамикой.</p>
<p>Природа, создавшая нервные системы, во многом подобна конструктору. Если мы правильно угадаем «исходные условия» и цели, стоявшие перед нею, а потом учтем их в своих разработках, то вынуждены будем получить аналогичный результат.</p>
<p>Примем в качестве «исходных условий» для нашей модели ряд свойств нервной системы, оговорившись сразу, что они носят приближенный характер.</p>

<h2>Автономность.</h2>
<p>Задача нервной системы — управлять организмом. Условие автономности означает то, что нервная система должна самостоятельно, без подсказок извне, находить способ управления. При этом нервная система заключена внутри организма и может взаимодействовать с окружающей средой лишь посредством рецепторов и эффекторов (исполняющих органов).</p>
<p>Заметим, что, даже если у нервной системы есть какие-то внешние «учителя», она все равно воспринимает их своими рецепторами. Что же касается неких «таинственных воздействий», способных проникать в нервную систему, минуя «штатные» входные каналы (рецепторы), здесь мы их учитывать не будем.</p>

<h2>Дискретность.</h2>
<p><b>Нервная система</b> — устройство во многом дискретное. На ее «входе» находятся рецепторы, которых может быть очень много, иногда несколько миллионов, но важно то, что число их конечно. </p>
<p>Состоит нервная система из отдельных (дискретных) объектов — <b>нейронов и нервных волокон</b>, которые обмениваются нервными импульсами — <b>дискретными сигналами</b>.<br>
На «выходе» нервной системы можно видеть большое, но тоже конечное число нервных окончаний, через которые исходят импульсы, управляющие работой исполнителей — мышц и желез.</p>
<p>Надо учитывать, конечно, что ряд параметров нейронов описывается непрерывными величинами. Это, например, размеры синапсов, «стыковочных узлов» нейрона и одновременно основных запоминающих устройств нервной системы. Кроме того, не вся информация передается в виде импульсов по нервным волокнам. На нейрон могут оказывать влияние также многочисленные метаболические процессы в организме.</p>

<h2>Начальная приспособленность.</h2>
<p>Нервная система как часть организма изначально приспособлена к условиям существования, в которых жили многие предшествующие поколения. В ходе длительного естественного отбора природа нашла оптимальные для данного организма рецепторы, исполнители, отделы нервной системы, связи между нейронами, выработала для нервной системы оптимальный «алгоритм» ее функционирования. </p>
<p>Змея, например, видит в инфракрасном диапазоне, а человек нет. Глаз лягушки хорошо видит лишь движущиеся точки, а человеческий глаз лучше распознает прямые линии. Собака, по-видимому, неспособна воспринять модель атома по Бору, а у человека нельзя сформировать образы из тысяч запахов, которыми оперирует собака.</p>
<p>Здесь важно заметить следующее. Ни в природе, ни в лаборатории нельзя создать распознающую систему, которая могла бы воспринять абсолютно все закономерности-образы входной информации. Она будет выделять образы только того вида, на который заранее настроена. Поэтому в нервной системе должны храниться «заготовки» всевозможных их видов.</p>
<p>За них-то и отвечает огромное число нейронов, большая часть которых остаются незадействованными в течение жизни человека. Однако никто не сможет сказать заранее, какие именно нейроны могут понадобиться. Избыток нейронов обеспечивает организму возможность адаптации.</p>

<h2>Минимум исходных знаний.</h2>
<p>После рождения организма, обладающего некоторой начальной приспособленностью и избытком нейронов, его нервная система начинает накапливать знания и информацию. Этот процесс продолжается в течение всей жизни организма (хотя одновременно идет и потеря знаний, например вследствие отмирания части нейронов). </p>
<p>Накопление информации происходит в нейронах, при этом изменяется смысл сигнала, представленного нервным импульсом. Например, до и после обучения нервная система может совершенно по-разному реагировать на одинаковые с виду нервные импульсы. </p>
<p>Здесь мы имеем дело с информационным процессом приспособления (адаптации), который и будем называть адаптивным управлением. Именно ему живые существа обязаны своей способностью распознавать образы, вырабатывать рефлексы, обучаться, принимать решения.
</p>

<h2>КАК РАБОТАЕТ НЕРВНАЯ СИСТЕМА</h2>
<p>Итак, начнем конструировать нашу управляющую систему (УС) как модель нервной системы, исходя из принятых выше четырех условий. Пусть она будет неким «черным ящиком», на который поступает дискретная «входная информация» от датчиков, а от него исходит «выходная информация» в виде команд исполнительным устройствам.</p>
<p>Попробуем представить себе процессы, происходящие внутри «черного ящика». Для этого посадим туда гипотетического наблюдателя — что-то вроде Демона Максвелла, сортировавшего молекулы в термодинамике. В соответствии с духом времени снабдим нашего Демона «сотовым телефоном», чтобы он мог передавать нам свои наблюдения.</p>

<h2>Итак, выходим на связь с Демоном.</h2>
<p><b>Сообщение 1.</b> «Я хочу выжить и, более того, хочу постоянно улучшать ощущение своего состояния».</p>
<p>Разумно: выживание и улучшение ощущения состояния есть цель управления нервной системы. При этом мы полагаем, что наш Демон «умный» и понимает, что в роли нервной системы он может выжить только вместе с телом и окружающей его средой, взаимодействуя с ней. Демон должен улучшать свое состояние таким образом, чтобы это не противоречило его выживанию. Например, для получения приятного «ощущения сытости», нервной системе нужно дать сигнал накормить подведомственное ей тело, а не раздражать какие-то свои нервные центры электродом или наркотиком. Кроме того, в результате естественного отбора «приятные» ощущения в некоторых состояниях должны соответствовать объективной пользе этих состояний для объекта управления.</p>
<p><b>Сообщение 2.</b> «Я должен активно действовать, чтобы находить новые возможности улучшать свое состояние. Для активных действий у меня есть кнопки, на которые я могу нажимать, и показания датчиков, на которые я могу смотреть».</p>
<p>Заметим, что активность — необходимая стратегия искомого принципа управления. Альтернативную стратегию — пассивное управление, когда система только реагирует на входные воздействия, — мы отвергаем, ибо она не ведет к поиску новых возможностей для улучшения состояния.</p>
<p>Зададим вопрос Демону: «Как вы определяете свое состояние, его улучшение и ухудшение?»</p>
<p><b>Сообщение 3.</b> «Не знаю, как я это делаю, но во мне есть некий «хорошеметр», аппарат эмоций, который позволяет мне чувствовать свое состояние в терминах «великолепно», «очень хорошо», «так себе», «плохо», «очень плохо», «невыносимо», а также его изменение в лучшую или худшую сторону. Видимо, оценка текущего состояния как-то зависит от входной информации и оценки уже сформировавшихся образов».</p>
<p>По-видимому, именно аппарат эмоций обеспечивает активность нервной системы. Если мы его отключим, Демон не захочет ничего делать, управление прекратится и объект управления погибнет.</p>
<p><b>Сообщение 4.</b> «Чтобы улучшить свое состояние, я должен найти способ управления. Для этого надо отыскать связи между моими действиями (нажатием кнопок) и показаниями датчиков, а также моими эмоциями».</p>
<p>Итак, Демон сформулировал еще одну целевую функцию: поиск и накопление знаний. Очевидно, что, чем больше знаний будет накоплено управляющей системой, тем более надежные способы выживания она сможет найти, тем успешнее сможет улучшать свое состояние. С другой стороны, чем дольше будет существовать объект, тем больше знаний он накопит. Поэтому обе целевые функции — выживание и накопление знаний — тесно связаны между собой (по нашему мнению, главная цель существования и есть накопление знаний).</p>
<p><b>Сообщение 5.</b> «Для начала попробую найти закономерности во входной информации».</p>
<p>Разумно. Но может ли Демон обнаружить закономерности в беспорядочном мелькании входных сигналов? Может, если он в состоянии заметить в них неслучайные совпадения. Если в какой-то момент ему покажется, что некоторую комбинацию сигналов он видит уже не в первый раз — значит, он сформировал образ.</p>
<p><b>Сообщение 6.</b> «Это красное пятно в нижнем углу правого монитора я уже видел! Постойте, но и этот одновременный скачок трех стрелок иногда повторяется».</p>
<p>Ну вот, уже два образа сформированы — номер 1 и номер 2. Это первые составляющие эмпирического знания нашей управляющей системы. Демон может занести их в свою Базу Знаний.</p>
<p><b>Сообщение 7. </b>«Теперь, когда образ номер 1 или номер 2 появляются в показаниях датчиков, я сразу узнаю их».</p>
<p>Сформированные образы (иначе их еще называют таксонами, паттернами, классами объектов) управляющая система может распознать в те моменты, когда в поле зрения датчиков появляются их прообразы.</p>
<p><b>Сообщение 8.</b> «Пытаюсь найти способы воздействия на образы номер 1 и номер 2. Для этого беспорядочно нажимаю на все имеющиеся кнопки».</p>
<p>А что еще остается делать, если нет никаких оснований для более разумной тактики. Интересно, что произойдет раньше: Демон найдет какую-либо закономерную связь между нажатием кнопки и реакцией образа либо выявится зависимость образов от эмоционального состояния Демона?</p>
<p>Сообщение 9.</b> «Всякий раз, когда я распознаю образ номер 1, мне становится «плохо». А когда распознаю образ номер 2, мое состояние никак не изменяется. Запомним это».</p>
<p>Ну вот, в данном случае первыми сформировались эмоциональные оценки образов. База Знаний пополнилась новой информацией.</p>
<p><b>Сообщение 10.</b> «Нашел! В 70% случаев, когда я нажимаю на кнопку номер 47, появляется образ номер 2, но только при условии, что в предыдущий момент был распознан образ номер 1».</p>
<p>Вот управляющая система и получила первое знание: в каких условиях, каким действием и с какой вероятностью вызывается (или вытесняется) определенный образ. Назовем нажатие на кнопку номер 47 действием номер 1.</p>
<p><b>Сообщение 11.</b> «Постойте, но точно такие же последствия имеет нажатие на кнопку номер 23! Запомним это».</p>
<p>Демон постепенно расширяет свою Базу Знаний, обнаруживая новые действия и уточняя найденные ранее.</p>
<p><b>Сообщение 12.</b> «Ура, наконец-то в своей Базе Знаний я нашел действия, которыми могу в некоторых условиях вызвать улучшение ощущения своего состояния!»</p>
<p>До этого момента все решения Демона были обусловлены задачей «накопить знания». Теперь он уже может принимать решения с целью «улучшить ощущение состояния».</p>
<p>Посмотрим, как он это делает. В некоторый момент времени управляющая система распознает несколько образов из числа ранее сформированных и определяет их среднюю эмоциональную оценку. </p>
<p>Затем она выбирает в Базе Знаний действие, которое в данных условиях обещает максимальное улучшение состояния. Если все варианты равнозначны, выбор может пасть на любой из них. Назовем такой способ первым механизмом принятия решений.</p>
<p><b>Сообщение 13.</b> «В некоторых постоянных условиях я совершаю одну и ту же последовательность действий — 12, 45, 38. Очередное действие я выбираю просто как продолжение этого ряда, то есть опять 12, 45, 38. (Так капитан шхуны, продвигаясь к цели, ведет ее сперва левым галсом, потом правым, потом снова левым и т. д., меняя галсы автоматически, не задумываясь.) </p>
<p>Эту последовательность (12, 45, 38) я запомнил как модель поведения номер 1 и теперь в подходящих случаях буду действовать по ней. Когда оценка состояния начнет ухудшаться либо когда ситуация решительно изменится, я от нее откажусь».</p>
<p>Появился второй механизм принятия решений: действия выбираются не на основе анализа текущего состояния, а по аналогии, в соответствии с обнаруженной закономерностью в последовательности ранее принятых решений.</p>
<p><b>Сообщение 14.</b> «Обнаружено сразу несколько моделей поведения для одних и тех же условий, я назвал их номер 2, номер 3 и номер 4. Которую же из них мне выбрать для управления? Догадался: я могу просчитать их по очереди, оценив и сравнив выигрыш, который обещает принести мне их реализация. Для этого я на свободные от важной информации входы буду последовательно подавать эти модели. Наибольший выигрыш даст модель номер 3, ее и буду выполнять».</p>
<p>Но это уже третий механизм принятия решений. Для него необходимо, чтобы управляющая система могла у самой себя вызвать распознавание образов — результатов действия, не совершая его.</p>
<p>Можно, например, представить себе, как расходятся круги по воде от брошенного камня, не бросая камень. Или сказать «равнобедренный треугольник» и увидеть этот треугольник. </p>
<p>Для этого лучше всего закрыть глаза и уши, то есть высвободить часть рецепторов от восприятия реальной информации. А управляющая система может реагировать на вызванные образы также не реальными действиями, а, например, только их словесным описанием. </p>
<p>Процесс внутреннего моделирования может продолжаться до тех пор, пока будут находиться понятия и образы, вызывающие друг друга. Нам представляется, что третий механизм наиболее интеллектуален, поскольку отражает способность организма к внутреннему моделированию-размышлению, возникновению языка, использованию его для общения с собой и с другими, выработке абстрактных представлений, прогнозированию и т. п.</p>

<h2>Что дальше?</h2>
<p>Теперь мы можем оставить Демона на какое-то время, поскольку сообщения его будут повторять по смыслу предыдущие. Если мы вернемся к нему несколько позже, то увидим, что:</p>
<p>а) в руках у Демона уже довольно пухлая тетрадь, содержащая обширную Базу Знаний,</p>
<p>б) он умеет распознавать множество образов,</p>
<p>в) почти в каждый момент он знает, как ему поступать в соответствии с обстоятельствами,</p>
<p>г) принимая решения, Демон уже учитывает их последствия, но далеко не все, хотя бы потому, что не успевает это сделать,</p>
<p>д) он может пообщаться сам с собой через внешнюю среду, как бы играя в жизнь и моделируя ситуации, а может статься, что Демон даже найдет во внешней среде другой такой же объект с Демоном внутри и вступит с ним во взаимодействие.</p>
<p>«Скачав» по телеметрии <b>Базу Знаний Демона</b>, мы многое узнаем о свойствах мира, в котором он живет. Фантастам же предлагаем подумать — что может представлять собой сочетание его Базы Знаний, аппарата эмоций и аппарата принятия решений, помещенных в новое тело.</p>

<h2>УСТРОЙСТВО УПРАВЛЯЮЩЕЙ СИСТЕМЫ</h2>
<p>Из сообщений Демона становится понятно, что управляющая система как модель нервной системы должна состоять из нескольких основных блоков, или подсистем: «формирования и распознавания образов», «аппарата эмоций», «формирования Базы Знаний», «принятия решений», «определения времени принятия решения».</p>
<q><p>Каждая подсистема решает свою задачу, учитывая результаты работы других подсистем.</p></q>
<p>Подсистема <b>«формирование и распознавание образов»</b> автоматически классифицирует входную информацию и распознает образы.</p>
<p>Подсистема <b>«аппарат эмоций»</b> дает эмоциональные оценки сформированных образов и текущего состояния.</p>
<p>Подсистема <b>«формирование Базы Знаний»</b> выявляет причинно-следственные связи в предыстории процесса управления и сохраняет их в памяти как новые знания.</p>
<p>Подсистема <b>«принятие решений»</b> отыскивает среди сформированных знаний действие, которое приводит к наибольшему приращению эмоциональной оценки состояния и наиболее высокой вероятности получения новых знаний.</p>
<p>Подсистема <b>«определение времени принятия решения»</b> оценивает, насколько быстро нужно принять очередное решение.</p>

<h2>Поясним подробнее работу последней подсистемы. </h2>
<p>Очевидно, что, чем хуже состояние и чем быстрее оно ухудшается, тем скорее требуется принять решение. Если просмотр всей Базы Знаний требует слишком больших затрат времени, управляющая система может просматривать лишь ее часть, учитывая только наиболее важные последствия того или иного решения. Неучтенные факторы будут реализовываться случайным для управляющей системы образом.</p>
<p>Например, увидев быстро наезжающий грузовик, мы принимаем решение отпрыгнуть в сторону, чтобы сохранить себе жизнь, и не учитываем второстепенных последствий: как мы будем выглядеть в глазах проходящей мимо дамы, не уроним ли шляпу, не наступим ли на газон и т. д. Если же мы распознали образ грузовика вдали, то, уходя в сторону, учтем и даму, и шляпу.</p>
<q><p>Некоторые из нас при значительном ухудшении ситуации впадают в заторможенное состояние, некоторые, напротив, становятся более активными. <br>
Индивидуальные особенности подсистемы «определение времени принятия решения» определяют тип нашего темперамента.</p></q>

<h2>МОДЕЛИ ИСКУССТВЕННЫХ НЕЙРОНОВ</h2>
<p>На практике обычно строят такие управляющие системы, которые решают лишь часть задач из вышеперечисленных, обычно одну-две. </p>
<p>Например, системы распознавания, как правило, не принимают самостоятельных решений: им заранее известно, что следует делать при распознавании того или иного образа.</p>
<p>Экспертные системы, напротив, строятся на базе уже готовых знаний, и им требуется только принимать решения. Некоторые системы занимаются решением исключительно поисковых и оптимизационных задач (так называемые генетические алгоритмы и другие подходы).</p>
<p>Гораздо сложнее создать систему управления, в которой решения всех перечисленных задач были бы взаимосвязаны, а исходные знания о свойствах объекта управления и среды допускали бы значительную неопределенность. </p>
<q><p>Трудность построения такой системы объясняется тем, что все ее части — подсистемы — должны учитывать результаты работы других подсистем в качестве своих исходных условий.</p></q>
<p>Поскольку наша научная группа придерживается <b>имитационного подхода</b> к моделированию нервной деятельности, мы строим модель управляющей системы по аналогии с естественными нервными системами. Подобно нервной системе, представляющей собою сеть нейронов, управляющая система тоже должна состоять из отдельных нейроноподобных элементов.</p>

<h2>Модели «искусственных нейронов»</h2>
<p><b>Модели «искусственных нейронов»</b> были разработаны еще в сороковых — пятидесятых годах. Они представляют собой простое устройство, которое суммирует входные сигналы, умноженные на веса (своего рода приоритеты), приписанные каждому отдельному входу, и сравнивает полученную сумму с заданным порогом. </p>
<p>Если сумма превысит порог, нейрон выдает на своем выходе сигнал «1», если нет — сигнал «0». Многослойную сеть из таких нейронов, в которой каждый получает сигналы от всех нейронов предыдущего слоя, можно обучить распознавать нужные образы. </p>
<p>Но предварительно необходимо подобрать веса на входах по определенному правилу, зависящему от того, какие образы нужно распознать.</p>
<p>Однако свойства такого <b>«искусственного нейрона»</b> нас не удовлетворяли, поскольку его отличия от природного представлялись значительными. В частности, нас не устраивало, что для настройки нейронов требовался внешний учитель, наблюдающий за всей нейросетью.</p>
<canter><img src="http://www.nkj.ru/upload/iblock/f0b4fdbbee089f6ca0ae6265fed06d48.jpg" alt="">
<p>Схема нейрона, используемого в традиционных нейросетях.<p></canter><br>
<q><p>Исходя из своего представления об управляющей системе, мы пришли к новой модели нейрона. Такой нейрон способен самостоятельно накапливать статистическую информацию о комбинациях входных сигналов. </p></q>
<p>Статистика накапливается в синапсах, размеры которых растут пропорционально числу наблюдений связанных друг с другом сигналов. В тот момент, когда нейрон вдруг «понимает», что некая комбинация входных сигналов не случайна, он изменяет свое состояние — становится обученным и в дальнейшем начинает узнавать ее, распознавать образ. </p>
<p>Образы, распознаваемые обученными нейронами, участвуют в формировании образов более высокого порядка. Чем более знакомым становится образ для нейрона, тем при более сильных помехах нейрон будет распознавать его.</p>
<p>Оказалось, что на базе таких нейронов можно конструировать сети, выполняющие функции всех перечисленных подсистем. При этом требуется определенный избыток нейронов, и он действительно существует в живых организмах: более 90% нейронов человека остаются незадействованными в течение его жизни. </p>
<q><p>Избыток искусственных нейронов в управляющей системе можно уменьшить и тем значительнее, чем более сложные связи между сигналами они способны обнаруживать, то есть за счет усложнения нейрона.</p></q>

<h2>СИСТЕМА АВТОНОМНОГО АДАПТИВНОГО УПРАВЛЕНИЯ</h2>
<p>Новая модель нейронов позволила разработать управляющую систему, названную нами системой <b>автономного адаптивного управления (ААУ)</b>. </p>
<p>Основное ее свойство — способность автоматически находить способ управления в соответствии с меняющимися окружающими условиями и свойствами объекта управления, а также развивать и корректировать этот способ. </p>
<center><img src="http://www.nkj.ru/upload/iblock/b7a6af8289f7457c20f6c7fa76ebf362.jpg" alt="">
<p>Модель нейрона, разработанная для метода автономного адаптивного управления.</p></center><br>
<q><p>Причем найденный однажды способ управления может быть «изъят» из системы и использован в работе другой системы, правда, уже в фиксированном виде.</p></q>
<p><b>Система автономного адаптивного управления</b> — <b>саморазвивающаяся система</b>. В ее поведении можно увидеть детерминированную и случайную компоненты. Первая опирается на уже накопленные знания и стремится улучшить состояние системы, наличие второй связано с отсутствием знаний и стремлением их накопить. </p>
<p>По мере накопления знаний поведение управляющей системы становится более детерминированным, что и отражает ее развитие. </p>
<p><b>Пример саморазвития ААУ</b> — последовательное появление у Демона трех механизмов принятия решения, каждый из которых вытекает из предыдущих и повышает эффективность управления.</p>
<q><p>Важно то, что в системе ААУ качество управления неуклонно растет, причем происходит это автоматически.</p></q>
<p>Как отмечалось выше, современная техника еще удовлетворяется управляющими системами, построенными либо только на основе системы распознавания, либо только на основе оптимизационных подходов и т. п. </p>
<center><img src="http://www.nkj.ru/upload/iblock/863560556d35f2e5eae10f1982c2e53c.jpg" alt="">
<p>Устройство управляющей системы как модели нервной системы. Такое устройство вынужденно вытекает из принятых нами в качестве исходных условий четырех свойств нервной системы.<p></center><br>
<p>Каждый из этих частных методов глубоко развит и способен давать результаты, с которыми трудно конкурировать любому новому подходу. Однако решение задачи управления в более общем виде с помощью метода автономного адаптивного управления имеет свои преимущества, которые проявляются со временем. Это и обнадеживает нас в наших исследованиях.</p>

<h2>ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ — АВТОНОМНЫЙ И ПОДЧИНЕННЫЙ</h2>
<p>Есть одно, на первый взгляд, странное обстоятельство. Предположим, сильно размечтавшись, что создана некая замечательная система автономного адаптивного управления, не уступающая по своим функциям пусть не человеку, не кошке, но хотя бы мышке (пока что и эта задача совершенно недостижима). </p>
<p>Какую же практическую пользу мы сможем извлечь из такой мышки? Заставим ее копать нору? </p>
<p>Она скажет: отпустите меня, я хочу есть, пить, гулять и меньше всего хочу работать на вас. И она будет права, так как цель описанной управляющей системы — улучшение своего (а не нашего) состояния.</p>
<p>В научном направлении, известном под названием <b>«системы искусственного интеллекта»</b>, есть некое лукавство. Провозглашая цель построить искусственный интеллект как модель природного, мы на самом деле хотим построить некоего неутомимого идеального Исполнителя наших задач и желаний, искусственного раба, что совсем не одно и то же.</p>
<p>Исполнитель может быть построен на любых принципах, удобных для хозяина (вспомним непреходящую мечту о скатерти-самобранке, волшебной палочке или Джинне из лампы Аладдина). </p>
<q><p>Соответствие естественным нервным системам при этом не только не требуется, но скорее оно даже излишне. </p></q>
<p>Примеры таких Исполнителей — современные «системы искусственного интеллекта»: экспертные, игровые и распознающие системы, лингвистические процессоры, промышленные роботы. </p>
<p>Они работают <b>по принципу «чего изволите?»</b>, их целевые функции и, следовательно, устройство подчинены интересам пользователя. Поэтому мы предлагаем именовать их системами <b>«Подчиненного Искусственного Интеллекта» (ПИИ)</b>.</p>
<q><p>Однако живые организмы не есть исполнители чужих заданий: они работают в первую очередь на себя. Это их естественное право. </p></q>
<p>Моделирование живых организмов — самостоятельное направление исследований. Мы предлагаем называть искусственные системы, моделирующие свойства естественных нервных систем как целого, <b>«Автономным Искусственным Интеллектом» (АИИ)</b>. Система автономного адаптивного управления замышлялась именно как АИИ.</p>
<p>С точки зрения познания природы интерес к созданию <b>«Автономного Искусственного Интеллекта»</b> очевиден, но и практическая польза от них может быть немалой. Подобные системы могут быть использованы для отработки методик обучения, общения, для моделирования различных психических отклонений и так далее. </p>
<p>Системы ААИ могут выполнять работы во вредных производствах, а также в труднодоступных для человека средах — в космосе, глубоко под водой и под землей. Они могут управлять быстропротекающими или, наоборот, очень медленными процессами, за которыми человеку следить крайне трудно. </p>
<p>В урезанном виде системы <b>«Автономного Искусственного Интеллекта»</b> могут быть использованы для управления разнообразными техническими устройствами.</p>
<p>Все это убеждает нас в необходимости исследования Автономного Искусственного Интеллекта и поиска возможностей его приложения.</p>

<h2>Детальное описание иллюстрации</h2>
<p>В биологических нейронах <b>входные сигналы</b> — <b>нервные импульсы</b> — поступают к нейрону (1) через контакты-синапсы, расположенные на отростках-дендритах (2), число которых может достигать тысячи. </p>
<img src="http://www.nkj.ru/upload/iblock/8523767f188229f9daeee7db4beb8aff.jpg" alt="">
<p><b>Выходом</b> нейрона служит длинный (до 1,5 метра) разветвляющийся отросток — аксон (3). </p>
<p>На синапсах и в теле нейрона происходит <b>логическая обработка</b> поступающих импульсов. При этом нейрон как бы решает, следует ли ему выдавать выходной сигнал на аксон или нет. <br>
Сначала нейрон «обучается», пытаясь отыскать неслучайные комбинации в потоке входных сигналов. Находя их, нейрон постепенно становится «обученным» и начинает узнавать эти комбинации, сообщая об этом выходным сигналом на своем аксоне.</p>
<p><b>Модель нейрона</b>, разработанная для метода автономного адаптивного управления. На вход нейрона поступают <b>«бинарные» сигналы</b> (типа 0 — 1, «да» — «нет») в виде одинаковых импульсов от датчиков или других нейронов. <br>
Импульсы попадают на элементы задержки (1), моделирующие задержку сигналов в синапсах, дендритах и т. п. </p>
<p><b>Элементы</b> (2) вырабатывают сигналы, соответствующие по длительности нервным импульсам. <br>
<b>Блок</b> (3) — основной элемент памяти нейрона. <br>
По мере «обучения» его синапсы растут, причем первыми пороговой величины достигают синапсы, соответствующие <b>неслучайным комбинациям входных сигналов</b>. </p>
<p>В дальнейшем эти комбинации будут распознаваться. Пройдя через схему <b>совпадений</b> (4), они вызовут появление выходного сигнала. Эти же импульсы, пройдя через блок задержки (5), восстанавливают исходное состояние нейрона.</p>
<p class="sourse">Источник материала: журнал «Наука и жизнь» (см. статьи академика В. Глушкова в №8, 1962 г.; № 6, 1965 г.; № 11, 1966 г.; № 2, 1971 г.; № 1, 1972 г.; № 9, 1978 г. и академика Н. Амосова в № 7, 1967 г.; № 5, 1989 г.).</p></article>